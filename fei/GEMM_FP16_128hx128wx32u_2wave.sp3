////////////////////////////////////////////////////////////////
///////////////implementation description///////////////////////
////////////////////////////////////////////////////////////////
////////////////////////////////////////////////////////////////
// design parameter for kernel development
// ThreadTile = 4x4  (ignore this for now; its vega20 )
// DepthU = 32
// WG= {16,32}
// MacroTile = 32x128
// 8 waves/WG; 2 waves/SIMD
// Matrix Instruction = mfma_f32_32x32x4bf16
//
// wave0 : primarily doing math in unroll loop and owns writing back 'C' elements back to memory
// wave1 : primarily doing global fetch in unroll loop 
// use double buffering of register and LDS  (equivalent of PLR=1 case in vega20)
// math wave & load wave use s_barrier  for synchronization

// kernel limitation
// - works only for alpha=1 & beta=0 
// - works only for problem sizes that are mulitple of 480x1024 


// High level synopsys on global fetch pattern
// each SIMD produce 64x32 elements  of output matrix 'C'. for DepthU=32 ,WG must fetch 64x32 elements of input matrix A,  32x128 elements of input Matrix B. each load wave (in total 4) responsible for fetching 16x32 elements of A and 32x32 elements of B.
// in terms of bytes (A) =  16x32x2 = 1024 bytes; each buffer_load_dword can fetch 256 bytes. in total we need 4 buffer_load_dword for A and 8 buffer_load_dword for B.

// global fetch pattern for A
// use WG number for calculating base address for A by mulitplying WG_number * A_stride_val; 
// each load wave fetch 16 rows , so use simd_id to calculate start of base address  of A for each wave
// 16 rows of 32 (K) elements: group 16 lanes to fetchi 32(K) elements for each row.  global fetch address register lane0-15 holds A[0][0-31], Lane16-31 holds fetch address for A[1][0-31], ...
// global fetch pattern for B
// each SIMD solves 32 columns for MT1 (128);  so use 32 to calculate start address for each SIMD load wave by multiplying 32*SIMD_ID*B_stride_val
// 

//////sreg def/////////////

var sgprKernArgAddress = 0 
var sgprWorkGroup0 = 2
var sgprWorkGroup1 = 3
var sgprWorkGroup2 = 4
var sgprNumWorkGroups0=5
var sgprNumWorkGroups1=6
var sgprSrdA=8
var sgprSrdB=12
var sgprSrdC=16
var sgprSrdD=20
var sgprTensor2dSizeC= 24
var sgprTensor2dSizeA= 26
var sgprTensor2dSizeB= 28
var sgprSaveExecMask= 30
var sgprAddressD= 32
var sgprAddressC= 34
var sgprStridesD= 36
var sgprStridesC= 38
var sgprAlpha= 40
var sgprBeta= 41
var sgprSizesFree = 42
var sgprSizesSum  = 45
var sgprLoopCounters= 46
var sgprOrigLoopCounter= 47
var sgprStridesA= 48
var sgprStridesB= 50
var sgprAddressA= 52
var sgprAddressB= 54
var sgprShadowLimitA= 56
var sgprShadowLimitB= 58
var sgprOrigStaggerUIter= 60
var sgprStaggerUIter= 61
var sgprWrapUA= 62
var sgprWrapUB= 64
var sgprNumFullBlocks= 66
var sgprWgmRemainder1= 67
var sgprMagicNumberWgmRemainder1= 68
var sgprGlobalReadIncsA= 69
var sgprGlobalReadIncsB= 70
var sgprScalarGlobalReadOffsetA=71
var sgprScalarGlobalReadOffsetB=74
var sgprLocalWriteAddrA=76
var sgprLocalWriteAddrB=78
var hw_id = 80
var sgprFetchSubGrpId=82


/////vreg def////////////////

var vgprValuC=0
var vgprAcc=0
var vgprValuA_X0_I0=32
var vgprG2LA=48
var vgprValuB_X0_I0=52
var vgprG2LB=68
var vgprLocalWriteAddrA=76
var vgprLocalWriteAddrB=78
var vgprGlobalReadOfvarA=82
var vgprGlobalReadOfvarB=90//[feifei-1215]
var vgprLocalReadAddrA=98
var vgprLocalReadAddrB=100
var vgprSerial=104
var vgprGlobalWriteOfvarC1=108
var vgprGlobalWriteOfvarC2=109
var vgprTmp=110

////constant def/////////////
var varlds_pad            = 8
var varlds_pad_qw         = varlds_pad >> 2
var varlds_Asize_per_wr   = 256+varlds_pad                  //each load inst load one 32X4 block.    need contiunous 32X4X2=256    bytes in LDS
var varlds_Asize_per_wave = varlds_Asize_per_wr * 8//[feifei-1215]   //each wave load 4 32X4 block one time.  need contiunous 32X4X4X2=1024 bytes in LDS
var varlds_Asize_per_wg   = varlds_Asize_per_wave * 4 //WG load 16 32X4 block(64X32) Matrix A to lds for pingpong.
var M_row_per_WG          = 64       //each WG process 64 row
var varlds_Bsize_per_wr   = 256+varlds_pad             //each load inst load one 32X4  block.    need contiunous 32X4X2=256     bytes in LDS
var varlds_Bsize_per_wave = varlds_Bsize_per_wr * 8   //each wave load seperate 32X64 block.    need contiunous 32X4X8X2=2048 bytes in LDS
var varlds_Bsize_per_wg   = varlds_Bsize_per_wave * 4  //WG load 64 32X4 block(32X256) Matrix B to lds for pingpong.
var varA_lds_base_addr    = 0
var varB_lds_base_addr    = varA_lds_base_addr + varlds_Asize_per_wg * 2  //in bytes

function v_regs(base, offset)
    var v_idx
    v_idx = base + offset
    return v[v_idx]
end

function s_regs(base, offset)
    var s_idx
    s_idx = base + offset
    return s[s_idx]
end

/******************************************/
/* 2GB limit - set offsets to -1 to exceed this and clamp */
/******************************************/
var BufferLimit=0x80000000

/******************************************/
/* Bits 127:96 of SRD.  Set DataFormat = 32 bit */
/******************************************/
var Srd127_96=0x0020000

var roundMaskVal=0xffff0000

var WT0=0x40
var WT0_LOG=0x6
var WT1=0x40
var WT1_LOG=0x6
var MT0=0x80
var MT1=0x80
var WPTTN0=MT0/WT0
var WPTTN0_LOG=0x1
var WPTTN0_MSK=0x1

shader main
  type(CS)

  user_sgpr_count(14)
  tgid_x_en(1)                                                  // s_tgid_x 
  tgid_y_en(1)                                                  // s_tgid_y
  tgid_z_en(1)                                                  // s_tgid_z 
  tidig_comp_cnt(2)

  // fetch kernel argument(s) required for building SRD(S) for global fetch A & B
  // this version use s_load_dword for fetch each kernel argument. there is another version
  // of kernel use s_load_dwordx4 to fetch kernel argument 

  /* Load Kernel Args */
  s_load_dword s[sgprTensor2dSizeA+0], s[sgprKernArgAddress:sgprKernArgAddress+1], 0x8 // 
  s_load_dword s[sgprTensor2dSizeA+1], s[sgprKernArgAddress:sgprKernArgAddress+1], 0xc // 
  s_load_dword s[sgprTensor2dSizeB+0], s[sgprKernArgAddress:sgprKernArgAddress+1], 0x10 // 
  s_load_dword s[sgprTensor2dSizeB+1], s[sgprKernArgAddress:sgprKernArgAddress+1], 0x14 // 
  s_load_dword s[sgprAddressA], s[sgprKernArgAddress:sgprKernArgAddress+1], 0x28 // 
  s_load_dword s[sgprAddressA+1], s[sgprKernArgAddress:sgprKernArgAddress+1], 0x2c // 
  s_load_dword s[sgprAddressB], s[sgprKernArgAddress:sgprKernArgAddress+1], 0x30 // 
  s_load_dword s[sgprAddressB+1], s[sgprKernArgAddress:sgprKernArgAddress+1], 0x34 // 
  s_load_dword s[sgprStridesA+0], s[sgprKernArgAddress:sgprKernArgAddress+1], 0x50 // 
  s_load_dword s[sgprStridesA+1], s[sgprKernArgAddress:sgprKernArgAddress+1], 0x54 // 
  s_load_dword s[sgprStridesB+0], s[sgprKernArgAddress:sgprKernArgAddress+1], 0x58 // 
  s_load_dword s[sgprStridesB+1], s[sgprKernArgAddress:sgprKernArgAddress+1], 0x5c // 
  s_load_dword s[sgprSizesSum+0], s[sgprKernArgAddress:sgprKernArgAddress+1], 0x6c // 


  s_mov_b32	        m0,0x3000					// LDS camp at 12288 bytes

  //vgprSerial  holds threadIdx 
  //vgprSerial+1  holds WaveFrontId (0-63)
  //vgprSerial+2  holds threadIdy  (wave0 =0 wave1 = 1)
  //vgprSerial+3  holds threadIdZ  (simd= 0,1,2,3)

  //HW_ID_REG
  //bit[0-3] //waveId
  //bit[5-4] //simdId
  //bit[11-8] //CuId

  v_mov_b32 	        v[vgprSerial], v0				//thread serial Id
  v_and_b32             v[vgprSerial+1], 0x3f, v0		        //threadId-x

  v_lshrrev_b32    	v2,  6,  v[vgprSerial]
  v_readfirstlane_b32   s[sgprFetchSubGrpId], v2

  //Fetchid -- wave that fetches 16 rows in 64;; uses simdId 
  s_getreg_b32          s[hw_id], hwreg(HW_REG_HW_ID)
  v_and_b32             v4, 0x30, s[hw_id]
  v_lshrrev_b32         v[vgprSerial+2], 4, v4					//simdId
  v_readfirstlane_b32   s[sgprFetchSubGrpId], v[vgprSerial+2]
  v_and_b32             v[vgprSerial+3], 0xf, s[hw_id]				//waveId
  v_readfirstlane_b32   s[hw_id+1], v[vgprSerial+3]

  // jump to different entry point for load wave (wave1 used for load wave; wave0 used for math wave)`
  s_cmp_eq_u32     s[hw_id+1], 1 
  s_cbranch_scc0   wave0_entry_start

  s_waitcnt lgkmcnt(0)                               // wait for 144 bytes of kern args

//WorkgroupId agnostic address calculation
//s[workGroup0] provides MT0 tile number  that this workgroup working 
//s[workGroup1] provides MT1 tile number that this workgroup working 
// use tle number to generate start address of the tile that this workgroup allocated too


  //Global read addresses: address A resource descriptor set-up
  //sgpr[0-1] - base address
  //sgpr[2]   - limit
  //sgpr[3]   - attributes

  //calculate base address for  A 
  //1. multiply MT0 size with TileNumber passed in s[sgprWorkGroup0]
  //2. multiply [1] result with stride[0] store result into 64-bit
  //3. the above two steps gives starting address of tile that this workgroup working


  s_mov_b32        s[sgprSrdA+0], s[sgprAddressA+0]		// SRD base = Address + tile_start
  s_mov_b32        s[sgprSrdA+1], s[sgprAddressA+1]		// SRD base = Address + tile_start
  s_mov_b32        s[sgprSrdA+3], Srd127_96				// set bits 127_96 in SRD
  s_mov_b32	   	   s[sgprSrdA+2], BufferLimit
  

  s_mul_i32        s84, s[sgprStridesA+0], 64		// workGroup[0]*MT
  s_mul_i32        s84, s[sgprWorkGroup0], s84		// workGroup[0]*MT
  s_lshl_b32       s85, s[sgprFetchSubGrpId], 4		// s85 = fetchId * x16 rows per wave
  s_mul_i32        s83, s85, s[sgprStridesA+0]		// wave start offset
  s_add_i32        s84, s84, s83


  
  //tile offset assignment a : global read address 
  //LVCA= 16 
  //glvw = 1
  v_lshrrev_b32    v0,    4, v[vgprSerial+1]			//sub-groupin
  v_mul_lo_u32     v4,    s[sgprStridesA+0],  v0		//mul d1 lower
  v_and_b32        v1,    15, v[vgprSerial+1]
  v_lshlrev_b32	   v1,    1,  v1
  v_add_co_u32     v[vgprGlobalReadOfvarA+0], vcc, v4, v1	//accumulate d1 lower
  v_add_u32        v[vgprGlobalReadOfvarA+0], s84, v[vgprGlobalReadOfvarA+0]
  v_lshlrev_b32    v[vgprGlobalReadOfvarA+0], 0x1, v[vgprGlobalReadOfvarA+0]  // offset *= bytes/element (x2)

   
  // why subtract lds_Asize_per_wr - A_lds_size_wr is used as inst_offset in buffer_load_dword lds:1
  s_lshl_b32       s[sgprScalarGlobalReadOffsetA+0],  s[sgprStridesA+0],    3   // X16 = X4(4 lines) X2(conver to bytes).  each buffer load process 4 lines.
  s_sub_u32        s[sgprScalarGlobalReadOffsetA+0],  s[sgprScalarGlobalReadOffsetA+0], varlds_Asize_per_wr
  
  for var i = 1; i < 8; i++
    v_add_u32         v_regs(vgprGlobalReadOfvarA,i), s[sgprScalarGlobalReadOffsetA+0],  v_regs(vgprGlobalReadOfvarA,i-1)
  end

/* local write addresses: first offset a */
  s_mov_b32        s[sgprLocalWriteAddrA+0], varlds_Asize_per_wave
  s_mul_i32        s[sgprLocalWriteAddrA+0], s[sgprFetchSubGrpId], s[sgprLocalWriteAddrA+0] //lds start address of each wave in bytes

/******************************************/
/* global read addresses: addresses b */
/******************************************/
  s_mov_b32        s[sgprSrdB+0], s[sgprAddressB+0]             // SRD base = Address + tile_start
  s_mov_b32        s[sgprSrdB+1], s[sgprAddressB+1]             // SRD base = Address + tile_start
  s_mov_b32        s[sgprSrdB+3], Srd127_96                     // set bits 127_96 in SRD
  s_mov_b32        s[sgprSrdB+2], BufferLimit

  s_mul_i32        s84,       s[sgprStridesB+0], 128            //workGroup[0]*MT
  s_mul_i32        s84,       s[sgprWorkGroup1], s84            //workGroup[0]*MT
  s_mul_i32        s85,       32, s[sgprStridesB+0]
  s_mul_i32        s85,       s[sgprFetchSubGrpId], s85
  s_add_i32        s84,       s84, s85

  //tile offset assignment b : global read address
  /* LVCA= 16 */
  //glvw = 1
  v_lshrrev_b32    v2,     4,  v[vgprSerial+1]
  v_and_b32        v3,     15, v[vgprSerial+1]
  v_lshlrev_b32	   v3,     1,  v3
  v_mul_lo_u32     v4,     s[sgprStridesB+0], v2                        //mul d1 lower
  v_add_co_u32     v[vgprGlobalReadOfvarB+0], vcc, v4,  v3              //accumulate d1 lower
  v_add_u32        v[vgprGlobalReadOfvarB+0], s84,  v[vgprGlobalReadOfvarB+0]           //accumulate d1 lower
  v_lshlrev_b32    v[vgprGlobalReadOfvarB+0], 0x1, v[vgprGlobalReadOfvarB+0]  // offset *= bytes/element


  s_lshl_b32       s[sgprScalarGlobalReadOffsetB+0], s[sgprStridesB+0],    3   // X16 = X4(4 lines) X2(conver to bytes).  each buffer load process 4 lines.
  s_sub_u32        s[sgprScalarGlobalReadOffsetB+0], s[sgprScalarGlobalReadOffsetB+0], varlds_Bsize_per_wr

// X16 = X4(4 lines) X2(conver to bytes).  each buffer load process 4 lines.
  for var i = 1; i < 8; i++
    v_add_u32         v_regs(vgprGlobalReadOfvarB,i), s[sgprScalarGlobalReadOffsetB+0],  v_regs(vgprGlobalReadOfvarB,i-1)
  end


/* local write addresses: first offset b */
  s_mov_b32        s[sgprLocalWriteAddrB+0], varlds_Bsize_per_wave
  s_mul_i32        s[sgprLocalWriteAddrB+0], s[sgprFetchSubGrpId], s[sgprLocalWriteAddrB+0]
  s_add_i32        s[sgprLocalWriteAddrB+0], s[sgprLocalWriteAddrB+0], varB_lds_base_addr


/**********************************************************************************************************************************/

  //////////////preload to LDS///////////
  //Fetch latency is about ~1000 of cycles
  //v_mfma_f32_32x32x8f16 => latency is 64 cycles 
  // we need deep software pipelining to hide read latency = MAC latency
  // unroll Depth = 32 
  // global prefetch next 2 unroll loop iteration
  // wait for first 32 iteration data to arrive
  // prefetch from  LDS A, B 
  // unroll loop start
  // 16 * 64 miMAC cycles 
  // LDS prefetch next 8 micro-iteration 

  // prefetch: Global to Local D2LDS
  // fetch 64x32 elements => each load fetch  4x32 elements / Wave
  // TODO : use dwordx4 buffer instruction 

  // sync all load waves before start fetching
  s_barrier

  s_mov_b32        m0,  s[sgprLocalWriteAddrA+0] //lds input offset
  s_add_i32        s[sgprLocalWriteAddrA+1], s[sgprLocalWriteAddrA+0], varlds_Asize_per_wg

  //PreFetch[0] A 16x32 elements/wave 
  buffer_load_dword v[vgprG2LA+0],  v[vgprGlobalReadOfvarA+0],  s[sgprSrdA:sgprSrdA+3], 0 offen:1 lds:1 offset:0
  buffer_load_dword v[vgprG2LA+1],  v[vgprGlobalReadOfvarA+1],  s[sgprSrdA:sgprSrdA+3], 0 offen:1 lds:1 offset:varlds_Asize_per_wr * 1
  s_nop 1
  buffer_load_dword v[vgprG2LA+2],  v[vgprGlobalReadOfvarA+2],  s[sgprSrdA:sgprSrdA+3], 0 offen:1 lds:1 offset:varlds_Asize_per_wr * 2
  buffer_load_dword v[vgprG2LA+3],  v[vgprGlobalReadOfvarA+3],  s[sgprSrdA:sgprSrdA+3], 0 offen:1 lds:1 offset:varlds_Asize_per_wr * 3
  s_nop 1
  buffer_load_dword v[vgprG2LA+4],  v[vgprGlobalReadOfvarA+4],  s[sgprSrdA:sgprSrdA+3], 0 offen:1 lds:1 offset:varlds_Asize_per_wr * 4
  buffer_load_dword v[vgprG2LA+5],  v[vgprGlobalReadOfvarA+5],  s[sgprSrdA:sgprSrdA+3], 0 offen:1 lds:1 offset:varlds_Asize_per_wr * 5
  s_nop 1
  buffer_load_dword v[vgprG2LA+6],  v[vgprGlobalReadOfvarA+6],  s[sgprSrdA:sgprSrdA+3], 0 offen:1 lds:1 offset:varlds_Asize_per_wr * 6
  buffer_load_dword v[vgprG2LA+7],  v[vgprGlobalReadOfvarA+7],  s[sgprSrdA:sgprSrdA+3], 0 offen:1 lds:1 offset:varlds_Asize_per_wr * 7

  s_mov_b32        m0,  s[sgprLocalWriteAddrB+0]     //lds offset B
  s_add_i32        s[sgprLocalWriteAddrB+1], s[sgprLocalWriteAddrB+0], varlds_Bsize_per_wg

  // prefetch[0]: Global to  LDS using LDS_DMA feature
  // fetch 64x32 elements => each load fetch  4x32 elements / Wave
  // TODO : Convert x4 fetch
  buffer_load_dword v[vgprG2LB+0],  v[vgprGlobalReadOfvarB+0],  s[sgprSrdB:sgprSrdB+3], 0 offen:1 lds:1 offset:0
  buffer_load_dword v[vgprG2LB+1],  v[vgprGlobalReadOfvarB+1],  s[sgprSrdB:sgprSrdB+3], 0 offen:1 lds:1 offset:varlds_Bsize_per_wr * 1
  s_nop 1
  buffer_load_dword v[vgprG2LB+2],  v[vgprGlobalReadOfvarB+2],  s[sgprSrdB:sgprSrdB+3], 0 offen:1 lds:1 offset:varlds_Bsize_per_wr * 2
  buffer_load_dword v[vgprG2LB+3],  v[vgprGlobalReadOfvarB+3],  s[sgprSrdB:sgprSrdB+3], 0 offen:1 lds:1 offset:varlds_Bsize_per_wr * 3
  s_nop 1
  buffer_load_dword v[vgprG2LB+4],  v[vgprGlobalReadOfvarB+4],  s[sgprSrdB:sgprSrdB+3], 0 offen:1 lds:1 offset:varlds_Bsize_per_wr * 4
  buffer_load_dword v[vgprG2LB+5],  v[vgprGlobalReadOfvarB+5],  s[sgprSrdB:sgprSrdB+3], 0 offen:1 lds:1 offset:varlds_Bsize_per_wr * 5
  s_nop 1
  buffer_load_dword v[vgprG2LB+6],  v[vgprGlobalReadOfvarB+6],  s[sgprSrdB:sgprSrdB+3], 0 offen:1 lds:1 offset:varlds_Bsize_per_wr * 6
  buffer_load_dword v[vgprG2LB+7],  v[vgprGlobalReadOfvarB+7],  s[sgprSrdB:sgprSrdB+3], 0 offen:1 lds:1 offset:varlds_Bsize_per_wr * 7

  // update LDS pointer For Fetch A[1]
  s_mov_b32  m0, s[sgprLocalWriteAddrA+1]
  // TODO ; avoid VALU instructions for increment; rather  use SGPR register for offset 
  //increment 32 elements to fetch next k=32 elements of tile 64x32
  for var i = 1; i < 8; i++
    v_add_u32         v_regs(vgprGlobalReadOfvarA,i), 64,  v_regs(vgprGlobalReadOfvarA,i-1)
    v_add_u32         v_regs(vgprGlobalReadOfvarB,i), 64,  v_regs(vgprGlobalReadOfvarB,i-1)
  end

  //PreFetch 2nd unroll loop iteration (2nd 32 k indices)
  buffer_load_dword v[vgprG2LA+0],  v[vgprGlobalReadOfvarA+0],  s[sgprSrdA:sgprSrdA+3], 0 offen:1 lds:1 offset:0
  buffer_load_dword v[vgprG2LA+1],  v[vgprGlobalReadOfvarA+1],  s[sgprSrdA:sgprSrdA+3], 0 offen:1 lds:1 offset:varlds_Asize_per_wr*1
  s_nop 1
  buffer_load_dword v[vgprG2LA+2],  v[vgprGlobalReadOfvarA+2],  s[sgprSrdA:sgprSrdA+3], 0 offen:1 lds:1 offset:varlds_Asize_per_wr*2
  buffer_load_dword v[vgprG2LA+3],  v[vgprGlobalReadOfvarA+3],  s[sgprSrdA:sgprSrdA+3], 0 offen:1 lds:1 offset:varlds_Asize_per_wr*3
  s_nop 1
  buffer_load_dword v[vgprG2LA+4],  v[vgprGlobalReadOfvarA+4],  s[sgprSrdA:sgprSrdA+3], 0 offen:1 lds:1 offset:varlds_Asize_per_wr * 4
  buffer_load_dword v[vgprG2LA+5],  v[vgprGlobalReadOfvarA+5],  s[sgprSrdA:sgprSrdA+3], 0 offen:1 lds:1 offset:varlds_Asize_per_wr * 5
  s_nop 1
  buffer_load_dword v[vgprG2LA+6],  v[vgprGlobalReadOfvarA+6],  s[sgprSrdA:sgprSrdA+3], 0 offen:1 lds:1 offset:varlds_Asize_per_wr * 6
  buffer_load_dword v[vgprG2LA+7],  v[vgprGlobalReadOfvarA+7],  s[sgprSrdA:sgprSrdA+3], 0 offen:1 lds:1 offset:varlds_Asize_per_wr * 7

  // update LDS pointer For Fetch B[1]
  s_mov_b32         m0,  s[sgprLocalWriteAddrB+1] //lds input offset
  s_nop 0

  buffer_load_dword v[vgprG2LB+0],  v[vgprGlobalReadOfvarB+0],  s[sgprSrdB:sgprSrdB+3], 0 offen:1 lds:1 offset:0
  buffer_load_dword v[vgprG2LB+1],  v[vgprGlobalReadOfvarB+1],  s[sgprSrdB:sgprSrdB+3], 0 offen:1 lds:1 offset:varlds_Bsize_per_wr*1
  s_nop 1
  buffer_load_dword v[vgprG2LB+2],  v[vgprGlobalReadOfvarB+2],  s[sgprSrdB:sgprSrdB+3], 0 offen:1 lds:1 offset:varlds_Bsize_per_wr*2
  buffer_load_dword v[vgprG2LB+3],  v[vgprGlobalReadOfvarB+3],  s[sgprSrdB:sgprSrdB+3], 0 offen:1 lds:1 offset:varlds_Bsize_per_wr*3
  s_nop 1
  buffer_load_dword v[vgprG2LB+4],  v[vgprGlobalReadOfvarB+4],  s[sgprSrdB:sgprSrdB+3], 0 offen:1 lds:1 offset:varlds_Bsize_per_wr*4
  buffer_load_dword v[vgprG2LB+5],  v[vgprGlobalReadOfvarB+5],  s[sgprSrdB:sgprSrdB+3], 0 offen:1 lds:1 offset:varlds_Bsize_per_wr*5
  s_nop 1
  buffer_load_dword v[vgprG2LB+6],  v[vgprGlobalReadOfvarB+6],  s[sgprSrdB:sgprSrdB+3], 0 offen:1 lds:1 offset:varlds_Bsize_per_wr*6
  buffer_load_dword v[vgprG2LB+7],  v[vgprGlobalReadOfvarB+7],  s[sgprSrdB:sgprSrdB+3], 0 offen:1 lds:1 offset:varlds_Bsize_per_wr*7

  //increment 32 elements to fetch next k=32 elements of tile 64x32
  for var i = 1; i < 8; i++
    v_add_u32         v_regs(vgprGlobalReadOfvarA,i), 64,  v_regs(vgprGlobalReadOfvarA,i-1)
    v_add_u32         v_regs(vgprGlobalReadOfvarB,i), 64,  v_regs(vgprGlobalReadOfvarB,i-1)
  end
  s_mov_b32     m0, s[sgprLocalWriteAddrA+0]

  s_waitcnt vmcnt(20)
  s_barrier
  s_waitcnt vmcnt(12)
  s_barrier

  s_lshr_b32       s[sgprLoopCounters+0], s[sgprSizesSum+0], 5 // s[sgprLoopCounters+0] = s[sgprSizesSum+0] / 32
  s_sub_u32	   s[sgprLoopCounters+0], 0x0, s[sgprLoopCounters+0]
  s_cmp_eq_u32     s[sgprLoopCounters+0], 0x0            // numIter0I == 0
  s_cbranch_scc1   label_0006                           // Dont enter Unroll Loop

 // unroll loop for load wave 

/******************************************/
/* Unrolled Loop(s) - Begin               */
/******************************************/
label_0005:

/**********************************************************************************************************************************/
  //Fetch A for Unroll iteration# (u+2) for 32 k indices
  buffer_load_dword v[vgprG2LA+0],  v[vgprGlobalReadOfvarA+0],  s[sgprSrdA:sgprSrdA+3], 0 offen:1 lds:1 offset:0
  buffer_load_dword v[vgprG2LA+1],  v[vgprGlobalReadOfvarA+1],  s[sgprSrdA:sgprSrdA+3], 0 offen:1 lds:1 offset:varlds_Asize_per_wr*1
  buffer_load_dword v[vgprG2LA+2],  v[vgprGlobalReadOfvarA+2],  s[sgprSrdA:sgprSrdA+3], 0 offen:1 lds:1 offset:varlds_Asize_per_wr*2
  buffer_load_dword v[vgprG2LA+3],  v[vgprGlobalReadOfvarA+3],  s[sgprSrdA:sgprSrdA+3], 0 offen:1 lds:1 offset:varlds_Asize_per_wr*3
  buffer_load_dword v[vgprG2LA+4],  v[vgprGlobalReadOfvarA+4],  s[sgprSrdA:sgprSrdA+3], 0 offen:1 lds:1 offset:varlds_Asize_per_wr * 4
  buffer_load_dword v[vgprG2LA+5],  v[vgprGlobalReadOfvarA+5],  s[sgprSrdA:sgprSrdA+3], 0 offen:1 lds:1 offset:varlds_Asize_per_wr * 5
  buffer_load_dword v[vgprG2LA+6],  v[vgprGlobalReadOfvarA+6],  s[sgprSrdA:sgprSrdA+3], 0 offen:1 lds:1 offset:varlds_Asize_per_wr * 6
  buffer_load_dword v[vgprG2LA+7],  v[vgprGlobalReadOfvarA+7],  s[sgprSrdA:sgprSrdA+3], 0 offen:1 lds:1 offset:varlds_Asize_per_wr * 7

  s_mov_b32     m0, s[sgprLocalWriteAddrB+0]
  s_nop 0
  //Fetch B for Unroll iteration# (u+2) for 32 k indices
  buffer_load_dword v[vgprG2LB+0],  v[vgprGlobalReadOfvarB+0],  s[sgprSrdB:sgprSrdB+3], 0 offen:1 lds:1 offset:0
  buffer_load_dword v[vgprG2LB+1],  v[vgprGlobalReadOfvarB+1],  s[sgprSrdB:sgprSrdB+3], 0 offen:1 lds:1 offset:varlds_Bsize_per_wr*1
  buffer_load_dword v[vgprG2LB+2],  v[vgprGlobalReadOfvarB+2],  s[sgprSrdB:sgprSrdB+3], 0 offen:1 lds:1 offset:varlds_Bsize_per_wr*2
  buffer_load_dword v[vgprG2LB+3],  v[vgprGlobalReadOfvarB+3],  s[sgprSrdB:sgprSrdB+3], 0 offen:1 lds:1 offset:varlds_Bsize_per_wr*3
  buffer_load_dword v[vgprG2LB+4],  v[vgprGlobalReadOfvarB+4],  s[sgprSrdB:sgprSrdB+3], 0 offen:1 lds:1 offset:varlds_Bsize_per_wr*4
  buffer_load_dword v[vgprG2LB+5],  v[vgprGlobalReadOfvarB+5],  s[sgprSrdB:sgprSrdB+3], 0 offen:1 lds:1 offset:varlds_Bsize_per_wr*5
  buffer_load_dword v[vgprG2LB+6],  v[vgprGlobalReadOfvarB+6],  s[sgprSrdB:sgprSrdB+3], 0 offen:1 lds:1 offset:varlds_Bsize_per_wr*6
  buffer_load_dword v[vgprG2LB+7],  v[vgprGlobalReadOfvarB+7],  s[sgprSrdB:sgprSrdB+3], 0 offen:1 lds:1 offset:varlds_Bsize_per_wr*7

  s_waitcnt vmcnt(20)
  // raise wave 1 priority for shSIMD & mai SIMD co-execution (bug in RTL stalls these VALU instruction while other wave doing MAI instruction
  s_setprio 1
  // synchronize with math wave to start fetching Matrix A elements for next unroll loop iteration
  s_barrier
  //increment 32 elements to fetch next k=32 elements of tile 64x32
  v_add_u32	v[vgprGlobalReadOfvarA+0], 64, v[vgprGlobalReadOfvarA+0]
  v_add_u32	v[vgprGlobalReadOfvarA+1], 64, v[vgprGlobalReadOfvarA+1]
  v_add_u32	v[vgprGlobalReadOfvarA+2], 64, v[vgprGlobalReadOfvarA+2]
  v_add_u32	v[vgprGlobalReadOfvarA+3], 64, v[vgprGlobalReadOfvarA+3]
  v_add_u32	v[vgprGlobalReadOfvarA+4], 64, v[vgprGlobalReadOfvarA+4]
  v_add_u32	v[vgprGlobalReadOfvarA+5], 64, v[vgprGlobalReadOfvarA+5]
  v_add_u32	v[vgprGlobalReadOfvarA+6], 64, v[vgprGlobalReadOfvarA+6]
  v_add_u32	v[vgprGlobalReadOfvarA+7], 64, v[vgprGlobalReadOfvarA+7]
  v_add_u32	v[vgprGlobalReadOfvarB+0], 64, v[vgprGlobalReadOfvarB+0]
  v_add_u32	v[vgprGlobalReadOfvarB+1], 64, v[vgprGlobalReadOfvarB+1]
  v_add_u32	v[vgprGlobalReadOfvarB+2], 64, v[vgprGlobalReadOfvarB+2]
  v_add_u32	v[vgprGlobalReadOfvarB+3], 64, v[vgprGlobalReadOfvarB+3]
  v_add_u32	v[vgprGlobalReadOfvarB+4], 64, v[vgprGlobalReadOfvarB+4]
  s_setprio 0
  s_waitcnt vmcnt(12)
  s_setprio 1
  // synchronize with math wave to start fetching Matrix B elements for next unroll loop iteration
  s_barrier
  v_add_u32	v[vgprGlobalReadOfvarB+5], 64, v[vgprGlobalReadOfvarB+5]
  v_add_u32	v[vgprGlobalReadOfvarB+6], 64, v[vgprGlobalReadOfvarB+6]
  v_add_u32	v[vgprGlobalReadOfvarB+7], 64, v[vgprGlobalReadOfvarB+7]
  s_setprio 0

  s_mov_b32     m0, s[sgprLocalWriteAddrA+1]
  s_add_u32     s[sgprLoopCounters+0], s[sgprLoopCounters+0], 0x1		//inc CounterL

  //*************************
  // Unroll Looop 1
  //**************************

  //Fetch A for Unroll iteration# (u+3) for 32 k indices
  buffer_load_dword v[vgprG2LA+0],  v[vgprGlobalReadOfvarA+0],  s[sgprSrdA:sgprSrdA+3], 0 offen:1 lds:1 offset:0
  buffer_load_dword v[vgprG2LA+1],  v[vgprGlobalReadOfvarA+1],  s[sgprSrdA:sgprSrdA+3], 0 offen:1 lds:1 offset:varlds_Asize_per_wr*1
  buffer_load_dword v[vgprG2LA+2],  v[vgprGlobalReadOfvarA+2],  s[sgprSrdA:sgprSrdA+3], 0 offen:1 lds:1 offset:varlds_Asize_per_wr*2
  buffer_load_dword v[vgprG2LA+3],  v[vgprGlobalReadOfvarA+3],  s[sgprSrdA:sgprSrdA+3], 0 offen:1 lds:1 offset:varlds_Asize_per_wr*3
  buffer_load_dword v[vgprG2LA+4],  v[vgprGlobalReadOfvarA+4],  s[sgprSrdA:sgprSrdA+3], 0 offen:1 lds:1 offset:varlds_Asize_per_wr * 4
  buffer_load_dword v[vgprG2LA+5],  v[vgprGlobalReadOfvarA+5],  s[sgprSrdA:sgprSrdA+3], 0 offen:1 lds:1 offset:varlds_Asize_per_wr * 5
  buffer_load_dword v[vgprG2LA+6],  v[vgprGlobalReadOfvarA+6],  s[sgprSrdA:sgprSrdA+3], 0 offen:1 lds:1 offset:varlds_Asize_per_wr * 6
  buffer_load_dword v[vgprG2LA+7],  v[vgprGlobalReadOfvarA+7],  s[sgprSrdA:sgprSrdA+3], 0 offen:1 lds:1 offset:varlds_Asize_per_wr * 7

  s_mov_b32     m0, s[sgprLocalWriteAddrB+1]
  s_nop 0
  //Fetch B for Unroll iteration# (u+2) for 32 k indices
  buffer_load_dword v[vgprG2LB+0],  v[vgprGlobalReadOfvarB+0],  s[sgprSrdB:sgprSrdB+3], 0 offen:1 lds:1 offset:0
  buffer_load_dword v[vgprG2LB+1],  v[vgprGlobalReadOfvarB+1],  s[sgprSrdB:sgprSrdB+3], 0 offen:1 lds:1 offset:varlds_Bsize_per_wr*1
  buffer_load_dword v[vgprG2LB+2],  v[vgprGlobalReadOfvarB+2],  s[sgprSrdB:sgprSrdB+3], 0 offen:1 lds:1 offset:varlds_Bsize_per_wr*2
  buffer_load_dword v[vgprG2LB+3],  v[vgprGlobalReadOfvarB+3],  s[sgprSrdB:sgprSrdB+3], 0 offen:1 lds:1 offset:varlds_Bsize_per_wr*3
  buffer_load_dword v[vgprG2LB+4],  v[vgprGlobalReadOfvarB+4],  s[sgprSrdB:sgprSrdB+3], 0 offen:1 lds:1 offset:varlds_Bsize_per_wr*4
  buffer_load_dword v[vgprG2LB+5],  v[vgprGlobalReadOfvarB+5],  s[sgprSrdB:sgprSrdB+3], 0 offen:1 lds:1 offset:varlds_Bsize_per_wr*5
  buffer_load_dword v[vgprG2LB+6],  v[vgprGlobalReadOfvarB+6],  s[sgprSrdB:sgprSrdB+3], 0 offen:1 lds:1 offset:varlds_Bsize_per_wr*6
  buffer_load_dword v[vgprG2LB+7],  v[vgprGlobalReadOfvarB+7],  s[sgprSrdB:sgprSrdB+3], 0 offen:1 lds:1 offset:varlds_Bsize_per_wr*7

  s_waitcnt vmcnt(20)
  s_barrier
  s_setprio 1	//raise the wave priority for simd co-execution
  //increment 32 elements to fetch next k=32 elements of tile 64x32
  v_add_u32	v[vgprGlobalReadOfvarA+0], 64, v[vgprGlobalReadOfvarA+0]
  v_add_u32	v[vgprGlobalReadOfvarA+1], 64, v[vgprGlobalReadOfvarA+1]
  v_add_u32	v[vgprGlobalReadOfvarA+2], 64, v[vgprGlobalReadOfvarA+2]
  v_add_u32	v[vgprGlobalReadOfvarA+3], 64, v[vgprGlobalReadOfvarA+3]
  v_add_u32	v[vgprGlobalReadOfvarA+4], 64, v[vgprGlobalReadOfvarA+4]
  v_add_u32	v[vgprGlobalReadOfvarA+5], 64, v[vgprGlobalReadOfvarA+5]
  v_add_u32	v[vgprGlobalReadOfvarA+6], 64, v[vgprGlobalReadOfvarA+6]
  v_add_u32	v[vgprGlobalReadOfvarA+7], 64, v[vgprGlobalReadOfvarA+7]
  v_add_u32	v[vgprGlobalReadOfvarB+0], 64, v[vgprGlobalReadOfvarB+0]
  v_add_u32	v[vgprGlobalReadOfvarB+1], 64, v[vgprGlobalReadOfvarB+1]
  v_add_u32	v[vgprGlobalReadOfvarB+2], 64, v[vgprGlobalReadOfvarB+2]
  v_add_u32	v[vgprGlobalReadOfvarB+3], 64, v[vgprGlobalReadOfvarB+3]
  v_add_u32	v[vgprGlobalReadOfvarB+4], 64, v[vgprGlobalReadOfvarB+4]
  s_setprio 0
  s_waitcnt vmcnt(12)
  s_barrier
  s_setprio 1
  v_add_u32	v[vgprGlobalReadOfvarB+5], 64, v[vgprGlobalReadOfvarB+5]
  v_add_u32	v[vgprGlobalReadOfvarB+6], 64, v[vgprGlobalReadOfvarB+6]
  v_add_u32	v[vgprGlobalReadOfvarB+7], 64, v[vgprGlobalReadOfvarB+7]
  s_setprio 0

  s_mov_b32     m0, s[sgprLocalWriteAddrA+0]
  s_add_u32     s[sgprLoopCounters+0], s[sgprLoopCounters+0], 0x1		//inc CounterL

  s_cmp_eq_i32  s[sgprLoopCounters+0], -0x2					// CounterL=0x2
  s_cbranch_scc0  label_0005

label_0006:
  s_waitcnt vmcnt(8)
  s_barrier
  s_waitcnt vmcnt(0)
  s_barrier

s_endpgm



wave0_entry_start:
/********************************************************************/
/********************************************************************/
  for var i =0; i < 16*4; i++
      v_accvgpr_write acc[vgprAcc+i], 0 
  end      

  // split kernel argument into two section one for math and another for math wave

  s_load_dword s[sgprAddressD], s[sgprKernArgAddress:sgprKernArgAddress+1], 0x18 // 
  s_load_dword s[sgprAddressD+1], s[sgprKernArgAddress:sgprKernArgAddress+1], 0x1c // 
  s_load_dword s[sgprAddressC], s[sgprKernArgAddress:sgprKernArgAddress+1], 0x20 // 
  s_load_dword s[sgprAddressC+1], s[sgprKernArgAddress:sgprKernArgAddress+1], 0x24 // 
  s_load_dword s[sgprTensor2dSizeC+0], s[sgprKernArgAddress:sgprKernArgAddress+1], 0x0 // 
  s_load_dword s[sgprTensor2dSizeC+1], s[sgprKernArgAddress:sgprKernArgAddress+1], 0x4 // 
  s_load_dword s[sgprAlpha], s[sgprKernArgAddress:sgprKernArgAddress+1], 0x38 // 
  //s_load_dword s[sgprBeta], s[sgprKernArgAddress:sgprKernArgAddress+1], 0x3c // load beta
  //s_load_dword s[sgprBeta+0], s[sgprKernArgAddress:sgprKernArgAddress+1], 0x3c //
  s_load_dword s[sgprStridesD+0], s[sgprKernArgAddress:sgprKernArgAddress+1], 0x40 // 
  s_load_dword s[sgprStridesD+1], s[sgprKernArgAddress:sgprKernArgAddress+1], 0x44 // 
  s_load_dword s[sgprStridesC+0], s[sgprKernArgAddress:sgprKernArgAddress+1], 0x48 // 
  s_load_dword s[sgprStridesC+1], s[sgprKernArgAddress:sgprKernArgAddress+1], 0x4c // 
  s_load_dword s[sgprSizesFree+0], s[sgprKernArgAddress:sgprKernArgAddress+1], 0x60 // 
  s_load_dword s[sgprSizesFree+1], s[sgprKernArgAddress:sgprKernArgAddress+1], 0x64 // 
  s_load_dword s[sgprSizesFree+2], s[sgprKernArgAddress:sgprKernArgAddress+1], 0x68 // 
  //s_load_dword s[sgprOrigStaggerUIter], s[sgprKernArgAddress:sgprKernArgAddress+1], 0x70 //
  //s_load_dword s[sgprNumWorkGroups0], s[sgprKernArgAddress:sgprKernArgAddress+1], 0x74 // 
  //s_load_dword s[sgprNumWorkGroups1], s[sgprKernArgAddress:sgprKernArgAddress+1], 0x78 // 
  //s_load_dword s[sgprNumFullBlocks], s[sgprKernArgAddress:sgprKernArgAddress+1], 0x84 // 
  //s_load_dword s[sgprWgmRemainder1], s[sgprKernArgAddress:sgprKernArgAddress+1], 0x88 // 
  //s_load_dword s[sgprMagicNumberWgmRemainder1], s[sgprKernArgAddress:sgprKernArgAddress+1], 0x8c // 

   s_barrier
   
/********************************************************************/
/* Local Read Addresses                   							*/
/********************************************************************/
 
  //32 lanes for holding M elements
  // local fetch address pattern should read M[0-31][0-1] in each DS_READ
  // global fetch used coalesce approach in fetching unrollD elements together and stored in LDS in that format
  // we need to cherry pick M[0-31] elements from LDS to load into VGPR. 
  v_and_b32        v1, v[vgprSerial+1],  0x1F			
  v_mul_lo_u32     v[vgprLocalReadAddrA+0],  16, v1		
  v_lshrrev_b32    v1, 2, v1							
  v_mul_lo_u32     v1, varlds_pad_qw, v1				
  v_add_u32        v[vgprLocalReadAddrA+0],  v1,  v[vgprLocalReadAddrA+0]

/* local read addresses: final offsets a */

  v_lshrrev_b32    v1, 5,  v[vgprSerial+1]	// thread_in_wave / mfma_mn(32)
  v_lshlrev_b32    v1, 1, v1 				// lane_id(dword) = thread_in_wave * mfma_k * e_sz / gpr_sz
  v_add_u32        v[vgprLocalReadAddrA+0], v1, v[vgprLocalReadAddrA+0]
  v_lshlrev_b32    v[vgprLocalReadAddrA+0], 2, v[vgprLocalReadAddrA+0]  //convert to bytes
  v_add_u32        v[vgprLocalReadAddrA+0], varA_lds_base_addr,  v[vgprLocalReadAddrA+0]
  v_add_u32        v[vgprLocalReadAddrA+1], varlds_Asize_per_wg, v[vgprLocalReadAddrA+0]

/********************************************************************/
/* Local Read Addresses Offset B          							*/
/********************************************************************/

  //32 lanes for holding N elements
  v_and_b32        v1,  v[vgprSerial+1],     0x1F		// thread_in_wave % mfma_mn(32)
  v_mul_lo_u32     v[vgprLocalReadAddrB+0],  16, v1
  v_lshrrev_b32    v1,  2,  v1
  v_mul_lo_u32     v1, varlds_pad_qw, v1
  v_add_u32        v[vgprLocalReadAddrB+0],  v1,  v[vgprLocalReadAddrB+0]

/* local read addresses: final offsets b */

  v_lshrrev_b32    v1,                  5,      v[vgprSerial+1]
  v_lshlrev_b32    v1, 1, v1 						// [feifei-1214]: second lane, 4elem in K-dim = 2dword 
  v_add_u32        v[vgprLocalReadAddrB+0],  v1, v[vgprLocalReadAddrB+0]
  v_lshlrev_b32    v[vgprLocalReadAddrB+0],  2, v[vgprLocalReadAddrB+0]  //convert to bytes

  s_mul_i32        s84,  s[sgprFetchSubGrpId],    varlds_Bsize_per_wave
  v_add_u32        v[vgprLocalReadAddrB+0], s84, v[vgprLocalReadAddrB+0]
  v_add_u32        v[vgprLocalReadAddrB+0],  varB_lds_base_addr,   v[vgprLocalReadAddrB+0]
  v_add_u32        v[vgprLocalReadAddrB+1], varlds_Bsize_per_wg, v[vgprLocalReadAddrB+0]

  s_waitcnt lgkmcnt(0)
  
/********************************************************************/
/* Global Address C calculation 									*/
/********************************************************************/
  s_mov_b32	   s[sgprSrdC+0], s[sgprAddressC+0]
  s_mov_b32	   s[sgprSrdC+1], s[sgprAddressC+1]
  s_mov_b32    s[sgprSrdC+2], 0x80000000
  s_mov_b32    s[sgprSrdC+3], Srd127_96

  s_mov_b32	   s[sgprSrdD+0], s[sgprAddressD+0]
  s_mov_b32    s[sgprSrdD+1], s[sgprAddressD+1]
  s_mov_b32    s[sgprSrdD+2], 0x80000000
  s_mov_b32    s[sgprSrdD+3], Srd127_96

  s_mul_i32	      s86, 0x80, s[sgprWorkGroup1]
  s_mul_hi_u32    s85, s86,  s[sgprStridesC+0]
  s_mul_i32       s84, s86,  s[sgprStridesC+0]
  s_lshl_b64      s[84:85],  s[84:85], 1
  s_add_u32       s[sgprSrdC+0], s[sgprSrdC+0], s84         
  s_addc_u32      s[sgprSrdC+1], s[sgprSrdC+1], s85         
  s_add_u32       s[sgprSrdD+0], s[sgprSrdD+0], s84         
  s_addc_u32      s[sgprSrdD+1], s[sgprSrdD+1], s85      

  // ----------------------------------------------------
  v_lshlrev_b32   v[vgprSerial], 6,    v[vgprSerial+2]
  v_add_u32       v[vgprSerial], v[vgprSerial+1], v[vgprSerial]
  v_and_b32	  	  v[vgprSerial+1], 0x3F, v[vgprSerial]	
	
  v_lshrrev_b32   v4, WPTTN0_LOG,  v[vgprSerial+2]
  v_lshlrev_b32   v4, WT1_LOG,  v4	        		
  v_mul_lo_u32    v3, v4,   s[sgprStridesC+0] 		
  v_and_b32	  	  v4, 0x1F, v[vgprSerial]			
  v_mul_lo_u32    v5, v4,   s[sgprStridesC+0]		
  v_add_u32	  	  v[vgprTmp+1], v3,  v5				
  v_and_b32   	  v3, WPTTN0_MSK, v[vgprSerial+2]
  v_lshlrev_b32   v3, WT0_LOG, v3					
  v_lshrrev_b32	  v6, 5,    v[vgprSerial+1]			
  v_lshlrev_b32   v6, 2,    v6						
  v_add_u32	  	  v6, v3,   v6						
  
  s_mul_i32	  	  s84, MT0, s[sgprWorkGroup0]		
  v_add_co_u32    v[vgprTmp], vcc, s84, v6			
  v_add_lshl_u32  v[vgprGlobalWriteOfvarC1], v[vgprTmp], v[vgprTmp+1], 0x1	// to byte
  v_lshlrev_b32   v4, 5, s[sgprStridesC+0]			// step(e) = stride * mfma_mn(32)
  v_lshlrev_b32   v4, 0x1, v4						// to byte
  v_add_u32       v[vgprGlobalWriteOfvarC2], v[vgprGlobalWriteOfvarC1], v4

/********************************************************************/
/********************************************************************/
  // total request 20, need return 4, so 20-4=16
  //Read A Elements from LDS into VREGS...  
  // one time burst read of A elements due to latency delay bbetween A and  B for first fetch
  // if elements are in L2 hit , you still have some latency between A and B for first fetch
  //  hide the latency by issuing bursts of A (fiqure out how many from profiler / thread trace)

  // [feifei-1215]:
  s_barrier
//  ds_read_b64       v[vgprValuA_X0_I0+0:vgprValuA_X0_I0+1],  v[vgprLocalReadAddrA+0]  offset:0  							// A m0,k0,p0
//  ds_read_b64       v[vgprValuA_X0_I0+2:vgprValuA_X0_I0+3],  v[vgprLocalReadAddrA+0]  offset:varlds_Asize_per_wr * 8 + 0	// A m1,k0,p0
//  ds_read_b64       v[vgprValuA_X0_I0+4:vgprValuA_X0_I0+5],  v[vgprLocalReadAddrA+0]  offset:16 							// A m0,k1,p0
//  ds_read_b64       v[vgprValuA_X0_I0+6:vgprValuA_X0_I0+7],  v[vgprLocalReadAddrA+0]  offset:varlds_Asize_per_wr * 8 + 16 	// A m1,k1,p0
//  ds_read_b64       v[vgprValuA_X0_I0+8:vgprValuA_X0_I0+9],    v[vgprLocalReadAddrA+0]  offset:32 							// A m0,k2,p0
//  ds_read_b64       v[vgprValuA_X0_I0+10:vgprValuA_X0_I0+11],  v[vgprLocalReadAddrA+0]  offset:varlds_Asize_per_wr * 8 + 32 // A m1,k2,p0
//  ds_read_b64       v[vgprValuA_X0_I0+12:vgprValuA_X0_I0+13],  v[vgprLocalReadAddrA+0]  offset:48 							// A m0,k3,p0
//  ds_read_b64       v[vgprValuA_X0_I0+14:vgprValuA_X0_I0+15],  v[vgprLocalReadAddrA+0]  offset:varlds_Asize_per_wr * 8 + 48 // A m1,k3,p0


  // Read B elements from LDS into VREGS
  // different strategy;; read as minimum as possible.  we need to get into unroll loop as soon as possible
  // Issue read for 8x32  B elements 
  // [feifei-1215]:
  s_barrier
//  ds_read_b64       v[vgprValuB_X0_I0+0:vgprValuB_X0_I0+1],    v[vgprLocalReadAddrB+0]  offset:0  							// B n0,k0,p0
//  ds_read_b64       v[vgprValuB_X0_I0+2:vgprValuB_X0_I0+3],    v[vgprLocalReadAddrB+0]  offset:varlds_Bsize_per_wr * 8 + 0  // B n1,k0,p0
//  ds_read_b64       v[vgprValuB_X0_I0+4:vgprValuB_X0_I0+5],    v[vgprLocalReadAddrB+0]  offset:16  							// B n0,k1,p0
//  ds_read_b64       v[vgprValuB_X0_I0+6:vgprValuB_X0_I0+7],    v[vgprLocalReadAddrB+0]  offset:varlds_Bsize_per_wr * 8 + 16 // B n1,k1,p0
//  ds_read_b64       v[vgprValuB_X0_I0+8:vgprValuB_X0_I0+9],    v[vgprLocalReadAddrB+0]  offset:32 							// B n0,k2,p0
//  ds_read_b64       v[vgprValuB_X0_I0+10:vgprValuB_X0_I0+11],  v[vgprLocalReadAddrB+0]  offset:varlds_Bsize_per_wr * 8 + 32 // B n1,k2,p0
//  ds_read_b64       v[vgprValuB_X0_I0+12:vgprValuB_X0_I0+13],  v[vgprLocalReadAddrB+0]  offset:48 							// B n0,k3,p0
//  ds_read_b64       v[vgprValuB_X0_I0+14:vgprValuB_X0_I0+15],  v[vgprLocalReadAddrB+0]  offset:varlds_Bsize_per_wr * 8 + 48 // B n1,k3,p0

  s_lshr_b32       s[sgprLoopCounters+0], s[sgprSizesSum+0], 5 // s[sgprLoopCounters+0] = s[sgprSizesSum+0] / 32
  s_sub_u32	       s[sgprLoopCounters+0], 0x0, s[sgprLoopCounters+0]
  s_cmp_eq_u32     s[sgprLoopCounters+0], 0x0            // numIter0I == 0
  s_cbranch_scc1   label_0004                           // Dont enter Loop


/******************************************/
/* Unrolled Loop(s) - Begin               */
/******************************************/
label_0001:

  //A matrix tile 64 rows
  //B matrix tile 128 columns
  //B matrix tile 128 columns split across 4 SIMD
  //A matrix tile split into 2 tiles 
  // unroll loop  k/32 times * 2 
  // each mfma caculates k=4 unroll iterations
  // 8 mfma for k=32  for each 32x32 ThreadTile.. (2 for 64 A rows)

  //unrolling double 
  //variable p for current iteration index
  // variable k for next iteration prefetch index calculation
/**********************************************************************************************************************************/
// [feifei-1215]: 4k,2m,1n,2p

	s_waitcnt lgkmcnt(0) // for test only !!!!!!!!!!!!!!!!!!!!!!!!!!
	v_mfma_f32_32x32x8f16   acc[vgprAcc+0]   ,   v[vgprValuA_X0_I0+0],   v[vgprValuB_X0_I0+0],  acc[vgprAcc+0]  // n0,m0,k0,p0
	v_mfma_f32_32x32x8f16   acc[vgprAcc+16]  ,   v[vgprValuA_X0_I0+2],   v[vgprValuB_X0_I0+0],  acc[vgprAcc+16] // n0,m1,k0,p0
	v_mfma_f32_32x32x8f16   acc[vgprAcc+32]  ,   v[vgprValuA_X0_I0+0],   v[vgprValuB_X0_I0+2],  acc[vgprAcc+32] // n1,m0,k0,p0
	v_mfma_f32_32x32x8f16   acc[vgprAcc+48]  ,   v[vgprValuA_X0_I0+2],   v[vgprValuB_X0_I0+2],  acc[vgprAcc+48] // n1,m1,k0,p0
	v_mfma_f32_32x32x8f16   acc[vgprAcc+0]   ,   v[vgprValuA_X0_I0+4],   v[vgprValuB_X0_I0+4],  acc[vgprAcc+0]  // n0,m0,k1,p0
	v_mfma_f32_32x32x8f16   acc[vgprAcc+16]  ,   v[vgprValuA_X0_I0+6],   v[vgprValuB_X0_I0+4],  acc[vgprAcc+16] // n0,m1,k1,p0
	v_mfma_f32_32x32x8f16   acc[vgprAcc+32]  ,   v[vgprValuA_X0_I0+4],   v[vgprValuB_X0_I0+6],  acc[vgprAcc+32] // n1,m0,k1,p0
	v_mfma_f32_32x32x8f16   acc[vgprAcc+48]  ,   v[vgprValuA_X0_I0+6],   v[vgprValuB_X0_I0+6],  acc[vgprAcc+48] // n1,m1,k1,p0

	s_waitcnt lgkmcnt(0) // need interleave after debug !!!!!!!!!!!!!!!!!!!!!!!!!!
	s_setprio 0 //lower wave priority other wave to execute valu instructions
	v_mfma_f32_32x32x8f16   acc[vgprAcc+0]   ,   v[vgprValuA_X0_I0+8 ], v[vgprValuB_X0_I0+8 ],acc[vgprAcc+0]  // n0,m0,k2,p0
	v_mfma_f32_32x32x8f16   acc[vgprAcc+16]  ,   v[vgprValuA_X0_I0+10], v[vgprValuB_X0_I0+8 ],acc[vgprAcc+16] // n0,m1,k2,p0
	v_mfma_f32_32x32x8f16   acc[vgprAcc+32]  ,   v[vgprValuA_X0_I0+8 ], v[vgprValuB_X0_I0+10],acc[vgprAcc+32] // n1,m0,k2,p0
	v_mfma_f32_32x32x8f16   acc[vgprAcc+48]  ,   v[vgprValuA_X0_I0+10], v[vgprValuB_X0_I0+10],acc[vgprAcc+48] // n1,m1,k2,p0
	v_mfma_f32_32x32x8f16   acc[vgprAcc+0]   ,   v[vgprValuA_X0_I0+12], v[vgprValuB_X0_I0+12],acc[vgprAcc+0]  // n0,m0,k3,p0
	v_mfma_f32_32x32x8f16   acc[vgprAcc+16]  ,   v[vgprValuA_X0_I0+14], v[vgprValuB_X0_I0+12],acc[vgprAcc+16] // n0,m1,k3,p0
	v_mfma_f32_32x32x8f16   acc[vgprAcc+32]  ,   v[vgprValuA_X0_I0+12], v[vgprValuB_X0_I0+14],acc[vgprAcc+32] // n1,m0,k3,p0
	v_mfma_f32_32x32x8f16   acc[vgprAcc+48]  ,   v[vgprValuA_X0_I0+14], v[vgprValuB_X0_I0+14],acc[vgprAcc+48] // n1,m1,k3,p0
	s_barrier // A pang
//	ds_read_b64       v[vgprValuA_X0_I0+0:vgprValuA_X0_I0+1],    v[vgprLocalReadAddrA+1]  offset:0  							// A m0,k0,p1
//	ds_read_b64       v[vgprValuA_X0_I0+2:vgprValuA_X0_I0+3],    v[vgprLocalReadAddrA+1]  offset:varlds_Asize_per_wr * 8 		// A m1,k0,p1
//	ds_read_b64       v[vgprValuA_X0_I0+4:vgprValuA_X0_I0+5],    v[vgprLocalReadAddrA+1]  offset:16 							// A m0,k1,p1
//	ds_read_b64       v[vgprValuA_X0_I0+6:vgprValuA_X0_I0+7],    v[vgprLocalReadAddrA+1]  offset:varlds_Asize_per_wr * 8 + 16 	// A m1,k1,p1
//	ds_read_b64       v[vgprValuA_X0_I0+8:vgprValuA_X0_I0+9],    v[vgprLocalReadAddrA+1]  offset:32 							// A m0,k2,p1
//	ds_read_b64       v[vgprValuA_X0_I0+10:vgprValuA_X0_I0+11],  v[vgprLocalReadAddrA+1]  offset:varlds_Asize_per_wr * 8 + 32 	// A m1,k2,p1
//	ds_read_b64       v[vgprValuA_X0_I0+12:vgprValuA_X0_I0+13],  v[vgprLocalReadAddrA+1]  offset:48 							// A m0,k3,p1
//	ds_read_b64       v[vgprValuA_X0_I0+14:vgprValuA_X0_I0+15],  v[vgprLocalReadAddrA+1]  offset:varlds_Asize_per_wr * 8 + 48 	// A m1,k3,p1
    s_barrier // B pang
//	ds_read_b64       v[vgprValuB_X0_I0+0:vgprValuB_X0_I0+1],    v[vgprLocalReadAddrB+1]  offset:0  							// B n0,k0,p1
//	ds_read_b64       v[vgprValuB_X0_I0+2:vgprValuB_X0_I0+3],    v[vgprLocalReadAddrB+1]  offset:varlds_Bsize_per_wr * 8 + 0  	// B n1,k0,p1
//	ds_read_b64       v[vgprValuB_X0_I0+4:vgprValuB_X0_I0+5],    v[vgprLocalReadAddrB+1]  offset:16  							// B n0,k1,p1
//	ds_read_b64       v[vgprValuB_X0_I0+6:vgprValuB_X0_I0+7],    v[vgprLocalReadAddrB+1]  offset:varlds_Bsize_per_wr * 8 + 16 	// B n1,k1,p1
//	ds_read_b64       v[vgprValuB_X0_I0+8:vgprValuB_X0_I0+9],    v[vgprLocalReadAddrB+1]  offset:32 							// B n0,k2,p1
//	ds_read_b64       v[vgprValuB_X0_I0+10:vgprValuB_X0_I0+11],  v[vgprLocalReadAddrB+1]  offset:varlds_Bsize_per_wr * 8 + 32 	// B n1,k2,p1
//	ds_read_b64       v[vgprValuB_X0_I0+12:vgprValuB_X0_I0+13],  v[vgprLocalReadAddrB+1]  offset:48 							// B n0,k3,p1
//	ds_read_b64       v[vgprValuB_X0_I0+14:vgprValuB_X0_I0+15],  v[vgprLocalReadAddrB+1]  offset:varlds_Bsize_per_wr * 8 + 48 	// B n1,k3,p1
	s_setprio 1
    s_add_u32 s[sgprLoopCounters+0], s[sgprLoopCounters+0], 0x1		//inc CounterL	
   //////////////////////////////////////////////

	s_waitcnt lgkmcnt(0) // for test only !!!!!!!!!!!!!!!!!!!!!!!!!!
	v_mfma_f32_32x32x8f16   acc[vgprAcc+0]   ,   v[vgprValuA_X0_I0+0],   v[vgprValuB_X0_I0+0],  acc[vgprAcc+0]  // n0,m0,k0,p1
	v_mfma_f32_32x32x8f16   acc[vgprAcc+16]  ,   v[vgprValuA_X0_I0+2],   v[vgprValuB_X0_I0+0],  acc[vgprAcc+16] // n0,m1,k0,p1
	v_mfma_f32_32x32x8f16   acc[vgprAcc+32]  ,   v[vgprValuA_X0_I0+0],   v[vgprValuB_X0_I0+2],  acc[vgprAcc+32] // n1,m0,k0,p1
	v_mfma_f32_32x32x8f16   acc[vgprAcc+48]  ,   v[vgprValuA_X0_I0+2],   v[vgprValuB_X0_I0+2],  acc[vgprAcc+48] // n1,m1,k0,p1
	v_mfma_f32_32x32x8f16   acc[vgprAcc+0]   ,   v[vgprValuA_X0_I0+4],   v[vgprValuB_X0_I0+4],  acc[vgprAcc+0]  // n0,m0,k1,p1
	v_mfma_f32_32x32x8f16   acc[vgprAcc+16]  ,   v[vgprValuA_X0_I0+6],   v[vgprValuB_X0_I0+4],  acc[vgprAcc+16] // n0,m1,k1,p1
	v_mfma_f32_32x32x8f16   acc[vgprAcc+32]  ,   v[vgprValuA_X0_I0+4],   v[vgprValuB_X0_I0+6],  acc[vgprAcc+32] // n1,m0,k1,p1
	v_mfma_f32_32x32x8f16   acc[vgprAcc+48]  ,   v[vgprValuA_X0_I0+6],   v[vgprValuB_X0_I0+6],  acc[vgprAcc+48] // n1,m1,k1,p1

	s_waitcnt lgkmcnt(0) // need interleave after debug !!!!!!!!!!!!!!!!!!!!!!!!!!
	s_setprio 0 //lower wave priority other wave to execute valu instructions
	v_mfma_f32_32x32x8f16   acc[vgprAcc+0]   ,   v[vgprValuA_X0_I0+8 ], v[vgprValuB_X0_I0+8 ],acc[vgprAcc+0]  // n0,m0,k2,p1
	v_mfma_f32_32x32x8f16   acc[vgprAcc+16]  ,   v[vgprValuA_X0_I0+10], v[vgprValuB_X0_I0+8 ],acc[vgprAcc+16] // n0,m1,k2,p1
	v_mfma_f32_32x32x8f16   acc[vgprAcc+32]  ,   v[vgprValuA_X0_I0+8 ], v[vgprValuB_X0_I0+10],acc[vgprAcc+32] // n1,m0,k2,p1
	v_mfma_f32_32x32x8f16   acc[vgprAcc+48]  ,   v[vgprValuA_X0_I0+10], v[vgprValuB_X0_I0+10],acc[vgprAcc+48] // n1,m1,k2,p1
	v_mfma_f32_32x32x8f16   acc[vgprAcc+0]   ,   v[vgprValuA_X0_I0+12], v[vgprValuB_X0_I0+12],acc[vgprAcc+0]  // n0,m0,k3,p1
	v_mfma_f32_32x32x8f16   acc[vgprAcc+16]  ,   v[vgprValuA_X0_I0+14], v[vgprValuB_X0_I0+12],acc[vgprAcc+16] // n0,m1,k3,p1
	v_mfma_f32_32x32x8f16   acc[vgprAcc+32]  ,   v[vgprValuA_X0_I0+12], v[vgprValuB_X0_I0+14],acc[vgprAcc+32] // n1,m0,k3,p1
	v_mfma_f32_32x32x8f16   acc[vgprAcc+48]  ,   v[vgprValuA_X0_I0+14], v[vgprValuB_X0_I0+14],acc[vgprAcc+48] // n1,m1,k3,p1
	s_barrier // A pang
//	ds_read_b64       v[vgprValuA_X0_I0+0:vgprValuA_X0_I0+1],    v[vgprLocalReadAddrA+0]  offset:0  							// A m0,k0,p0
//	ds_read_b64       v[vgprValuA_X0_I0+2:vgprValuA_X0_I0+3],    v[vgprLocalReadAddrA+0]  offset:varlds_Asize_per_wr * 8 + 0  	// A m1,k0,p0
//	ds_read_b64       v[vgprValuA_X0_I0+4:vgprValuA_X0_I0+5],    v[vgprLocalReadAddrA+0]  offset:16 							// A m0,k1,p0
//	ds_read_b64       v[vgprValuA_X0_I0+6:vgprValuA_X0_I0+7],    v[vgprLocalReadAddrA+0]  offset:varlds_Asize_per_wr * 8 + 16 	// A m1,k1,p0
//	ds_read_b64       v[vgprValuA_X0_I0+8:vgprValuA_X0_I0+9],    v[vgprLocalReadAddrA+0]  offset:32 							// A m0,k2,p0
//	ds_read_b64       v[vgprValuA_X0_I0+10:vgprValuA_X0_I0+11],  v[vgprLocalReadAddrA+0]  offset:varlds_Asize_per_wr * 8 + 32 	// A m1,k2,p0
//	ds_read_b64       v[vgprValuA_X0_I0+12:vgprValuA_X0_I0+13],  v[vgprLocalReadAddrA+0]  offset:48 							// A m0,k3,p0
//	ds_read_b64       v[vgprValuA_X0_I0+14:vgprValuA_X0_I0+15],  v[vgprLocalReadAddrA+0]  offset:varlds_Asize_per_wr * 8 + 48 	// A m1,k3,p0
    s_barrier // B pang
//	ds_read_b64       v[vgprValuB_X0_I0+0:vgprValuB_X0_I0+1],    v[vgprLocalReadAddrB+0]  offset:0  							// B n0,k0,p0
//	ds_read_b64       v[vgprValuB_X0_I0+2:vgprValuB_X0_I0+3],    v[vgprLocalReadAddrB+0]  offset:varlds_Bsize_per_wr * 8 + 0  	// B n1,k0,p0
//	ds_read_b64       v[vgprValuB_X0_I0+4:vgprValuB_X0_I0+5],    v[vgprLocalReadAddrB+0]  offset:16  							// B n0,k1,p0
//	ds_read_b64       v[vgprValuB_X0_I0+6:vgprValuB_X0_I0+7],    v[vgprLocalReadAddrB+0]  offset:varlds_Bsize_per_wr * 8 + 16 	// B n1,k1,p0
//	ds_read_b64       v[vgprValuB_X0_I0+8:vgprValuB_X0_I0+9],    v[vgprLocalReadAddrB+0]  offset:32 							// B n0,k2,p0
//	ds_read_b64       v[vgprValuB_X0_I0+10:vgprValuB_X0_I0+11],  v[vgprLocalReadAddrB+0]  offset:varlds_Bsize_per_wr * 8 + 32 	// B n1,k2,p0
//	ds_read_b64       v[vgprValuB_X0_I0+12:vgprValuB_X0_I0+13],  v[vgprLocalReadAddrB+0]  offset:48 							// B n0,k3,p0
//	ds_read_b64       v[vgprValuB_X0_I0+14:vgprValuB_X0_I0+15],  v[vgprLocalReadAddrB+0]  offset:varlds_Bsize_per_wr * 8 + 48 	// B n1,k3,p0
    s_setprio 1
    s_add_u32 s[sgprLoopCounters+0], s[sgprLoopCounters+0], 0x1		//inc CounterL
	
   s_cmp_eq_i32  s[sgprLoopCounters+0], -0x2					// CounterL=0x2
   s_cbranch_scc0  label_0001
/**********************************************************************************************************************************/

label_0002:

/******************************************/
/*  NoLoadLoop - Begin											
/******************************************/
// [feifei-1215]: 4k,2m,1n,2p

	s_waitcnt lgkmcnt(0) // for test only !!!!!!!!!!!!!!!!!!!!!!!!!!
	v_mfma_f32_32x32x8f16   acc[vgprAcc+0]   ,   v[vgprValuA_X0_I0+0],   v[vgprValuB_X0_I0+0],  acc[vgprAcc+0]  // n0,m0,k0,p0
	v_mfma_f32_32x32x8f16   acc[vgprAcc+16]  ,   v[vgprValuA_X0_I0+2],   v[vgprValuB_X0_I0+0],  acc[vgprAcc+16] // n0,m1,k0,p0
	v_mfma_f32_32x32x8f16   acc[vgprAcc+32]  ,   v[vgprValuA_X0_I0+0],   v[vgprValuB_X0_I0+2],  acc[vgprAcc+32] // n1,m0,k0,p0
	v_mfma_f32_32x32x8f16   acc[vgprAcc+48]  ,   v[vgprValuA_X0_I0+2],   v[vgprValuB_X0_I0+2],  acc[vgprAcc+48] // n1,m1,k0,p0
	v_mfma_f32_32x32x8f16   acc[vgprAcc+0]   ,   v[vgprValuA_X0_I0+4],   v[vgprValuB_X0_I0+4],  acc[vgprAcc+0]  // n0,m0,k1,p0
	v_mfma_f32_32x32x8f16   acc[vgprAcc+16]  ,   v[vgprValuA_X0_I0+6],   v[vgprValuB_X0_I0+4],  acc[vgprAcc+16] // n0,m1,k1,p0
	v_mfma_f32_32x32x8f16   acc[vgprAcc+32]  ,   v[vgprValuA_X0_I0+4],   v[vgprValuB_X0_I0+6],  acc[vgprAcc+32] // n1,m0,k1,p0
	v_mfma_f32_32x32x8f16   acc[vgprAcc+48]  ,   v[vgprValuA_X0_I0+6],   v[vgprValuB_X0_I0+6],  acc[vgprAcc+48] // n1,m1,k1,p0

	s_waitcnt lgkmcnt(0) // need interleave after debug !!!!!!!!!!!!!!!!!!!!!!!!!!
	v_mfma_f32_32x32x8f16   acc[vgprAcc+0]   ,   v[vgprValuA_X0_I0+8 ], v[vgprValuB_X0_I0+8 ],acc[vgprAcc+0]  // n0,m0,k2,p0
	v_mfma_f32_32x32x8f16   acc[vgprAcc+16]  ,   v[vgprValuA_X0_I0+10], v[vgprValuB_X0_I0+8 ],acc[vgprAcc+16] // n0,m1,k2,p0
	v_mfma_f32_32x32x8f16   acc[vgprAcc+32]  ,   v[vgprValuA_X0_I0+8 ], v[vgprValuB_X0_I0+10],acc[vgprAcc+32] // n1,m0,k2,p0
	v_mfma_f32_32x32x8f16   acc[vgprAcc+48]  ,   v[vgprValuA_X0_I0+10], v[vgprValuB_X0_I0+10],acc[vgprAcc+48] // n1,m1,k2,p0
	v_mfma_f32_32x32x8f16   acc[vgprAcc+0]   ,   v[vgprValuA_X0_I0+12], v[vgprValuB_X0_I0+12],acc[vgprAcc+0]  // n0,m0,k3,p0
	v_mfma_f32_32x32x8f16   acc[vgprAcc+16]  ,   v[vgprValuA_X0_I0+14], v[vgprValuB_X0_I0+12],acc[vgprAcc+16] // n0,m1,k3,p0
	v_mfma_f32_32x32x8f16   acc[vgprAcc+32]  ,   v[vgprValuA_X0_I0+12], v[vgprValuB_X0_I0+14],acc[vgprAcc+32] // n1,m0,k3,p0
	v_mfma_f32_32x32x8f16   acc[vgprAcc+48]  ,   v[vgprValuA_X0_I0+14], v[vgprValuB_X0_I0+14],acc[vgprAcc+48] // n1,m1,k3,p0
	
	s_barrier // A pang
//	ds_read_b64       v[vgprValuA_X0_I0+0:vgprValuA_X0_I0+1],    v[vgprLocalReadAddrA+1]  offset:0  							// A m0,k0,p1
//	ds_read_b64       v[vgprValuA_X0_I0+2:vgprValuA_X0_I0+3],    v[vgprLocalReadAddrA+1]  offset:varlds_Asize_per_wr * 8 		// A m1,k0,p1
//	ds_read_b64       v[vgprValuA_X0_I0+4:vgprValuA_X0_I0+5],    v[vgprLocalReadAddrA+1]  offset:16 							// A m0,k1,p1
//	ds_read_b64       v[vgprValuA_X0_I0+6:vgprValuA_X0_I0+7],    v[vgprLocalReadAddrA+1]  offset:varlds_Asize_per_wr * 8 + 16 	// A m1,k1,p1
//	ds_read_b64       v[vgprValuA_X0_I0+8:vgprValuA_X0_I0+9],    v[vgprLocalReadAddrA+1]  offset:32 							// A m0,k2,p1
//	ds_read_b64       v[vgprValuA_X0_I0+10:vgprValuA_X0_I0+11],  v[vgprLocalReadAddrA+1]  offset:varlds_Asize_per_wr * 8 + 32 	// A m1,k2,p1
//	ds_read_b64       v[vgprValuA_X0_I0+12:vgprValuA_X0_I0+13],  v[vgprLocalReadAddrA+1]  offset:48 							// A m0,k3,p1
//	ds_read_b64       v[vgprValuA_X0_I0+14:vgprValuA_X0_I0+15],  v[vgprLocalReadAddrA+1]  offset:varlds_Asize_per_wr * 8 + 48 	// A m1,k3,p1
    s_barrier // B pang
//	ds_read_b64       v[vgprValuB_X0_I0+0:vgprValuB_X0_I0+1],    v[vgprLocalReadAddrB+1]  offset:0  							// B n0,k0,p1
//	ds_read_b64       v[vgprValuB_X0_I0+2:vgprValuB_X0_I0+3],    v[vgprLocalReadAddrB+1]  offset:varlds_Bsize_per_wr * 8 + 0  	// B n1,k0,p1
//	ds_read_b64       v[vgprValuB_X0_I0+4:vgprValuB_X0_I0+5],    v[vgprLocalReadAddrB+1]  offset:16  							// B n0,k1,p1
//	ds_read_b64       v[vgprValuB_X0_I0+6:vgprValuB_X0_I0+7],    v[vgprLocalReadAddrB+1]  offset:varlds_Bsize_per_wr * 8 + 16 	// B n1,k1,p1
//	ds_read_b64       v[vgprValuB_X0_I0+8:vgprValuB_X0_I0+9],    v[vgprLocalReadAddrB+1]  offset:32 							// B n0,k2,p1
//	ds_read_b64       v[vgprValuB_X0_I0+10:vgprValuB_X0_I0+11],  v[vgprLocalReadAddrB+1]  offset:varlds_Bsize_per_wr * 8 + 32 	// B n1,k2,p1
//	ds_read_b64       v[vgprValuB_X0_I0+12:vgprValuB_X0_I0+13],  v[vgprLocalReadAddrB+1]  offset:48 							// B n0,k3,p1
//	ds_read_b64       v[vgprValuB_X0_I0+14:vgprValuB_X0_I0+15],  v[vgprLocalReadAddrB+1]  offset:varlds_Bsize_per_wr * 8 + 48 	// B n1,k3,p1

   //////////////////////////////////////////////

	s_waitcnt lgkmcnt(0) // for test only
	v_mfma_f32_32x32x8f16   acc[vgprAcc+0]   ,   v[vgprValuA_X0_I0+0],   v[vgprValuB_X0_I0+0],  acc[vgprAcc+0]  // n0,m0,k0,p1
	v_mfma_f32_32x32x8f16   acc[vgprAcc+16]  ,   v[vgprValuA_X0_I0+2],   v[vgprValuB_X0_I0+0],  acc[vgprAcc+16] // n0,m1,k0,p1
	v_mfma_f32_32x32x8f16   acc[vgprAcc+32]  ,   v[vgprValuA_X0_I0+0],   v[vgprValuB_X0_I0+2],  acc[vgprAcc+32] // n1,m0,k0,p1
	v_mfma_f32_32x32x8f16   acc[vgprAcc+48]  ,   v[vgprValuA_X0_I0+2],   v[vgprValuB_X0_I0+2],  acc[vgprAcc+48] // n1,m1,k0,p1
	v_mfma_f32_32x32x8f16   acc[vgprAcc+0]   ,   v[vgprValuA_X0_I0+4],   v[vgprValuB_X0_I0+4],  acc[vgprAcc+0]  // n0,m0,k1,p1
	v_mfma_f32_32x32x8f16   acc[vgprAcc+16]  ,   v[vgprValuA_X0_I0+6],   v[vgprValuB_X0_I0+4],  acc[vgprAcc+16] // n0,m1,k1,p1
	v_mfma_f32_32x32x8f16   acc[vgprAcc+32]  ,   v[vgprValuA_X0_I0+4],   v[vgprValuB_X0_I0+6],  acc[vgprAcc+32] // n1,m0,k1,p1
	v_mfma_f32_32x32x8f16   acc[vgprAcc+48]  ,   v[vgprValuA_X0_I0+6],   v[vgprValuB_X0_I0+6],  acc[vgprAcc+48] // n1,m1,k1,p1

	s_waitcnt lgkmcnt(0) // need interleave !!!!!!!!!!!!!!!!!!!!!!!!!!
	s_setprio 0 //lower wave priority other wave to execute valu instructions
	v_mfma_f32_32x32x8f16   acc[vgprAcc+0]   ,   v[vgprValuA_X0_I0+8 ], v[vgprValuB_X0_I0+8 ],acc[vgprAcc+0]  // n0,m0,k2,p1
	v_mfma_f32_32x32x8f16   acc[vgprAcc+16]  ,   v[vgprValuA_X0_I0+10], v[vgprValuB_X0_I0+8 ],acc[vgprAcc+16] // n0,m1,k2,p1
	v_mfma_f32_32x32x8f16   acc[vgprAcc+32]  ,   v[vgprValuA_X0_I0+8 ], v[vgprValuB_X0_I0+10],acc[vgprAcc+32] // n1,m0,k2,p1
	v_mfma_f32_32x32x8f16   acc[vgprAcc+48]  ,   v[vgprValuA_X0_I0+10], v[vgprValuB_X0_I0+10],acc[vgprAcc+48] // n1,m1,k2,p1
	v_mfma_f32_32x32x8f16   acc[vgprAcc+0]   ,   v[vgprValuA_X0_I0+12], v[vgprValuB_X0_I0+12],acc[vgprAcc+0]  // n0,m0,k3,p1
	v_mfma_f32_32x32x8f16   acc[vgprAcc+16]  ,   v[vgprValuA_X0_I0+14], v[vgprValuB_X0_I0+12],acc[vgprAcc+16] // n0,m1,k3,p1
	v_mfma_f32_32x32x8f16   acc[vgprAcc+32]  ,   v[vgprValuA_X0_I0+12], v[vgprValuB_X0_I0+14],acc[vgprAcc+32] // n1,m0,k3,p1
	v_mfma_f32_32x32x8f16   acc[vgprAcc+48]  ,   v[vgprValuA_X0_I0+14], v[vgprValuB_X0_I0+14],acc[vgprAcc+48] // n1,m1,k3,p1

	s_waitcnt lgkmcnt(0) // need interleave after debug !!!!!!!!!!!!!!!!!!!!!!!!!!
	
/********************************************************************/
/* store_c:															*/
/********************************************************************/	
	for var j = 0; j < 8; j++ // read C0~C7// n0,m0
//		v_accvgpr_read v_regs(vgprValuC, j), acc[vgprAcc+j+0*16]
//		v_cvt_f16_f32 v_regs(vgprValuC, j),v_regs(vgprValuC, j)
		v_mov_b32 v[vgprValuC+j], 0x1
		v_cvt_f16_u16 v[vgprValuC+j], v[vgprValuC+j]
	end
	v_pack_b32_f16 v[vgprValuC+0],v[vgprValuC+0],v[vgprValuC+1] // C0 = C1 | C0
	v_pack_b32_f16 v[vgprValuC+1],v[vgprValuC+2],v[vgprValuC+3] // C1 = C3 | C2
	v_pack_b32_f16 v[vgprValuC+2],v[vgprValuC+4],v[vgprValuC+5] // C2 = C5 | C4
	v_pack_b32_f16 v[vgprValuC+3],v[vgprValuC+6],v[vgprValuC+7] // C3 = C7 | C6
	buffer_store_dwordx2 v[vgprValuC+0:vgprValuC+1],v[vgprGlobalWriteOfvarC1],  s[sgprSrdD:sgprSrdD+3], 0 offset:64*0+ 0 offen:1
	buffer_store_dwordx2 v[vgprValuC+2:vgprValuC+3],v[vgprGlobalWriteOfvarC1],  s[sgprSrdD:sgprSrdD+3], 0 offset:64*0+16 offen:1
	// ----------------------------------------------------
	for var j = 8; j < 16; j++ // read C8~C15// n0,m0
//		v_accvgpr_read v_regs(vgprValuC, j), acc[vgprAcc+j+0*16]
//		v_cvt_f16_f32 v_regs(vgprValuC, j),v_regs(vgprValuC, j)
		v_mov_b32 v[vgprValuC+j], 0x2
		v_cvt_f16_u16 v[vgprValuC+j], v[vgprValuC+j]
	end	  
	v_pack_b32_f16 v[vgprValuC+4],v[vgprValuC+8], v[vgprValuC+9]  // C4 = C9 | C8
	v_pack_b32_f16 v[vgprValuC+5],v[vgprValuC+10],v[vgprValuC+11] // C5 = C11 | C10
	v_pack_b32_f16 v[vgprValuC+6],v[vgprValuC+12],v[vgprValuC+13] // C6 = C13 | C12
	v_pack_b32_f16 v[vgprValuC+7],v[vgprValuC+14],v[vgprValuC+15] // C7 = C15 | C14
	buffer_store_dwordx2 v[vgprValuC+4:vgprValuC+5],v[vgprGlobalWriteOfvarC1],  s[sgprSrdD:sgprSrdD+3], 0 offset:64*0+32 offen:1
	buffer_store_dwordx2 v[vgprValuC+6:vgprValuC+7],v[vgprGlobalWriteOfvarC1],  s[sgprSrdD:sgprSrdD+3], 0 offset:64*0+48 offen:1
	// ----------------------------------------------------
	for var j = 0; j < 8; j++ // read C16~C23 -> C0~C7// n0,m1
//		v_accvgpr_read v_regs(vgprValuC, j), acc[vgprAcc+j+1*16]
//		v_cvt_f16_f32 v_regs(vgprValuC, j),v_regs(vgprValuC, j)
		v_mov_b32 v[vgprValuC+j], 0x3
		v_cvt_f16_u16 v[vgprValuC+j], v[vgprValuC+j]
	end
	v_pack_b32_f16 v[vgprValuC+0],v[vgprValuC+0],v[vgprValuC+1] // C0 = C1 | C0
	v_pack_b32_f16 v[vgprValuC+1],v[vgprValuC+2],v[vgprValuC+3] // C1 = C3 | C2
	v_pack_b32_f16 v[vgprValuC+2],v[vgprValuC+4],v[vgprValuC+5] // C2 = C5 | C4
	v_pack_b32_f16 v[vgprValuC+3],v[vgprValuC+6],v[vgprValuC+7] // C3 = C7 | C6
	buffer_store_dwordx2 v[vgprValuC+0:vgprValuC+1],v[vgprGlobalWriteOfvarC1],  s[sgprSrdD:sgprSrdD+3], 0 offset:64*1+ 0 offen:1
	buffer_store_dwordx2 v[vgprValuC+2:vgprValuC+3],v[vgprGlobalWriteOfvarC1],  s[sgprSrdD:sgprSrdD+3], 0 offset:64*1+16 offen:1
	// ----------------------------------------------------
	for var j = 8; j < 16; j++ // read C24~C32 -> C8~C15// n0,m1
//		v_accvgpr_read v_regs(vgprValuC, j), acc[vgprAcc+j+1*16]
//		v_cvt_f16_f32 v_regs(vgprValuC, j),v_regs(vgprValuC, j)
		v_mov_b32 v[vgprValuC+j], 0x4
		v_cvt_f16_u16 v[vgprValuC+j], v[vgprValuC+j]
	end
	v_pack_b32_f16 v[vgprValuC+4],v[vgprValuC+8], v[vgprValuC+9]  // C4 = C9 | C8
	v_pack_b32_f16 v[vgprValuC+5],v[vgprValuC+10],v[vgprValuC+11] // C5 = C11 | C10
	v_pack_b32_f16 v[vgprValuC+6],v[vgprValuC+12],v[vgprValuC+13] // C6 = C13 | C12
	v_pack_b32_f16 v[vgprValuC+7],v[vgprValuC+14],v[vgprValuC+15] // C7 = C15 | C14
	buffer_store_dwordx2 v[vgprValuC+4:vgprValuC+5],v[vgprGlobalWriteOfvarC1],  s[sgprSrdD:sgprSrdD+3], 0 offset:64*1+32 offen:1
	buffer_store_dwordx2 v[vgprValuC+6:vgprValuC+7],v[vgprGlobalWriteOfvarC1],  s[sgprSrdD:sgprSrdD+3], 0 offset:64*1+48 offen:1
	// ----------------------------------------------------
	for var j = 0; j < 8; j++ // read C16~C23 -> C0~C7// n1,m0
//		v_accvgpr_read v_regs(vgprValuC, j), acc[vgprAcc+j+2*16]
//		v_cvt_f16_f32 v_regs(vgprValuC, j),v_regs(vgprValuC, j)
		v_mov_b32 v[vgprValuC+j], 0x5
		v_cvt_f16_u16 v[vgprValuC+j], v[vgprValuC+j]
	end
	v_pack_b32_f16 v[vgprValuC+0],v[vgprValuC+0],v[vgprValuC+1] // C0 = C1 | C0
	v_pack_b32_f16 v[vgprValuC+1],v[vgprValuC+2],v[vgprValuC+3] // C1 = C3 | C2
	v_pack_b32_f16 v[vgprValuC+2],v[vgprValuC+4],v[vgprValuC+5] // C2 = C5 | C4
	v_pack_b32_f16 v[vgprValuC+3],v[vgprValuC+6],v[vgprValuC+7] // C3 = C7 | C6
	buffer_store_dwordx2 v[vgprValuC+0:vgprValuC+1],v[vgprGlobalWriteOfvarC2],  s[sgprSrdD:sgprSrdD+3], 0 offset:64*0+ 0 offen:1
	buffer_store_dwordx2 v[vgprValuC+2:vgprValuC+3],v[vgprGlobalWriteOfvarC2],  s[sgprSrdD:sgprSrdD+3], 0 offset:64*0+16 offen:1
	// ----------------------------------------------------
	for var j = 8; j < 16; j++ // read C24~C32 -> C8~C15// n1,m0
//		v_accvgpr_read v_regs(vgprValuC, j), acc[vgprAcc+j+2*16]
//		v_cvt_f16_f32 v_regs(vgprValuC, j),v_regs(vgprValuC, j)
		v_mov_b32 v[vgprValuC+j], 0x6
		v_cvt_f16_u16 v[vgprValuC+j], v[vgprValuC+j]
	end
	v_pack_b32_f16 v[vgprValuC+4],v[vgprValuC+8], v[vgprValuC+9]  // C4 = C9 | C8
	v_pack_b32_f16 v[vgprValuC+5],v[vgprValuC+10],v[vgprValuC+11] // C5 = C11 | C10
	v_pack_b32_f16 v[vgprValuC+6],v[vgprValuC+12],v[vgprValuC+13] // C6 = C13 | C12
	v_pack_b32_f16 v[vgprValuC+7],v[vgprValuC+14],v[vgprValuC+15] // C7 = C15 | C14
	buffer_store_dwordx2 v[vgprValuC+4:vgprValuC+5],v[vgprGlobalWriteOfvarC2],  s[sgprSrdD:sgprSrdD+3], 0 offset:64*0+32 offen:1
	buffer_store_dwordx2 v[vgprValuC+6:vgprValuC+7],v[vgprGlobalWriteOfvarC2],  s[sgprSrdD:sgprSrdD+3], 0 offset:64*0+48 offen:1
	// ----------------------------------------------------
	for var j = 0; j < 8; j++ // read C16~C23 -> C0~C7// n1,m1
//		v_accvgpr_read v_regs(vgprValuC, j), acc[vgprAcc+j+3*16]
//		v_cvt_f16_f32 v_regs(vgprValuC, j),v_regs(vgprValuC, j)
		v_mov_b32 v[vgprValuC+j], 0x7
		v_cvt_f16_u16 v[vgprValuC+j], v[vgprValuC+j]
	end
	v_pack_b32_f16 v[vgprValuC+0],v[vgprValuC+0],v[vgprValuC+1] // C0 = C1 | C0
	v_pack_b32_f16 v[vgprValuC+1],v[vgprValuC+2],v[vgprValuC+3] // C1 = C3 | C2
	v_pack_b32_f16 v[vgprValuC+2],v[vgprValuC+4],v[vgprValuC+5] // C2 = C5 | C4
	v_pack_b32_f16 v[vgprValuC+3],v[vgprValuC+6],v[vgprValuC+7] // C3 = C7 | C6
	buffer_store_dwordx2 v[vgprValuC+0:vgprValuC+1],v[vgprGlobalWriteOfvarC2],  s[sgprSrdD:sgprSrdD+3], 0 offset:64*1+ 0 offen:1
	buffer_store_dwordx2 v[vgprValuC+2:vgprValuC+3],v[vgprGlobalWriteOfvarC2],  s[sgprSrdD:sgprSrdD+3], 0 offset:64*1+16 offen:1
	// ----------------------------------------------------
	for var j = 8; j < 16; j++ // read C24~C32 -> C8~C15// n1,m1
//		v_accvgpr_read v_regs(vgprValuC, j), acc[vgprAcc+j+3*16]
//		v_cvt_f16_f32 v_regs(vgprValuC, j),v_regs(vgprValuC, j)
		v_mov_b32 v[vgprValuC+j], 0x8
		v_cvt_f16_u16 v[vgprValuC+j], v[vgprValuC+j]
	end
	v_pack_b32_f16 v[vgprValuC+4],v[vgprValuC+8], v[vgprValuC+9]  // C4 = C9 | C8
	v_pack_b32_f16 v[vgprValuC+5],v[vgprValuC+10],v[vgprValuC+11] // C5 = C11 | C10
	v_pack_b32_f16 v[vgprValuC+6],v[vgprValuC+12],v[vgprValuC+13] // C6 = C13 | C12
	v_pack_b32_f16 v[vgprValuC+7],v[vgprValuC+14],v[vgprValuC+15] // C7 = C15 | C14
	buffer_store_dwordx2 v[vgprValuC+4:vgprValuC+5],v[vgprGlobalWriteOfvarC2],  s[sgprSrdD:sgprSrdD+3], 0 offset:64*1+32 offen:1
	buffer_store_dwordx2 v[vgprValuC+6:vgprValuC+7],v[vgprGlobalWriteOfvarC2],  s[sgprSrdD:sgprSrdD+3], 0 offset:64*1+48 offen:1

/********************************************************************/
/********************************************************************/
label_0004:
  s_waitcnt        0  
  s_endpgm                                          



end
